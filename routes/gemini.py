from fastapi import APIRouter, HTTPException, Depends, Body
from fastapi.responses import JSONResponse
import google.generativeai as genai
from pydantic import BaseModel, Field
from typing import Dict, Any, Optional, Union
from config.jwt_bearer import JWTBearer
from config.config import Settings
import os
import base64
import re
import json
import logging
from datetime import datetime

router = APIRouter()

# Configure the Gemini API
settings = Settings()
api_key = settings.GEMINI_API_KEY 
if api_key:
    genai.configure(api_key=api_key)
else:
    raise ValueError("GEMINI_API_KEY environment variable is not set")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

ACNE_TYPE_MAPPING = {
    "blackhead": "M·ª•n ƒë·∫ßu ƒëen",
    "whitehead": "M·ª•n ƒë·∫ßu tr·∫Øng", 
    "papular": "M·ª•n s∆∞ng ƒë·ªè",
    "pustular": "M·ª•n m·ªß",
    "nodular": "M·ª•n b·ªçc",
    "cystic": "M·ª•n nang",
    "comedonal": "M·ª•n c√°m",
    "acne": "M·ª•n tr·ª©ng c√°"
}

def load_prompt_from_file(prompt_type: str = "default") -> str:
    """
    Load specific prompt from markdown file based on prompt type.
    
    Args:
        prompt_type: Type of prompt to load (default, assessment, recommendations, etc.)
    
    Returns:
        Loaded prompt content
    
    Raises:
        FileNotFoundError: If prompt file is not found
        ValueError: If prompt section is not found in file
        Exception: If any other error occurs while loading
    """
    try:
        prompt_file_path = os.path.join("docs", "gemini_prompts.md")
        if not os.path.exists(prompt_file_path):
            raise FileNotFoundError(f"Prompt file not found: {prompt_file_path}")
            
        with open(prompt_file_path, "r", encoding="utf-8") as f:
            content = f.read()
            
        section_mapping = {
            "default": r"## Default Skin Analysis Prompt\n(.*?)(?=\n##|\Z)",
            "assessment": r"## Skin Assessment Prompt\n(.*?)(?=\n##|\Z)",
            "safe_recommendations": r"## Safe Recommendations Prompt\n(.*?)(?=\n##|\Z)",
            "medical_disclaimer": r"## Medical Disclaimer\n(.*?)(?=\n##|\Z)"
        }
        
        pattern = section_mapping.get(prompt_type, section_mapping["default"])
        prompt_match = re.search(pattern, content, re.DOTALL)
        
        if prompt_match:
            logger.info(f"Successfully loaded {prompt_type} prompt from file")
            return prompt_match.group(1).strip()
        else:
            raise ValueError(f"Section {prompt_type} not found in prompt file")
            
    except (FileNotFoundError, ValueError) as e:
        logger.error(f"Error loading prompt file: {e}")
        raise e
    except Exception as e:
        logger.error(f"Unexpected error loading prompt file: {e}")
        raise Exception(f"Failed to load prompt: {str(e)}")

class GeminiRequest(BaseModel):
    image_base64: str = Field(..., description="Base64 encoded image for analysis")
    class_summary: Optional[Dict[str, Dict[str, Any]]] = Field(None, description="Pre-detected acne summary (optional)")
    custom_prompt: Optional[str] = Field(None, description="Custom analysis prompt (optional)")
    analysis_type: Optional[str] = Field("default", description="Type of analysis: default, assessment, safe_recommendations")

    model_config = {
        "json_schema_extra": {
            "example": {
                "image_base64": "base64_encoded_image_string",
                "class_summary": {
                    "blackhead": {"count": 5, "color": "#1E2761"},
                    "papular": {"count": 2, "color": "#FF5722"},
                    "pustular": {"count": 1, "color": "#FF9800"}
                },
                "analysis_type": "safe_recommendations",
                "custom_prompt": "T·∫≠p trung v√†o routine chƒÉm s√≥c d·ªãu nh·∫π"
            }
        }
    }

def fix_base64_padding(b64_string: str) -> str:
    """Fixes base64 string padding if necessary."""
    if not b64_string:
        return b64_string
    
    b64_string = b64_string.strip()
    b64_string = re.sub(r'\s+', '', b64_string)
    
    if b64_string.startswith('data:image'):
        b64_string = b64_string.split(',', 1)[1] if ',' in b64_string else b64_string
    
    missing_padding = len(b64_string) % 4
    if missing_padding:
        b64_string += '=' * (4 - missing_padding)
    
    return b64_string



def build_enhanced_safe_prompt(
    class_summary: Optional[Dict[str, Dict[str, Any]]] = None, 
    analysis_type: str = "default",
    custom_prompt: Optional[str] = None
) -> str:
    """Build comprehensive skin analysis prompt - AI analyzes image directly."""
    
    # If class_summary is provided, use it as additional info
    additional_info = ""
    if class_summary:
        total_count = 0
        condition_details = []
        
        for condition, details in class_summary.items():
            count = details.get('count', 0)
            total_count += count
            vietnamese_name = ACNE_TYPE_MAPPING.get(condition.lower(), condition.capitalize())
            condition_details.append(f"- **{vietnamese_name}**: {count} v·ªã tr√≠")
        
        # Determine severity level
        if total_count < 5:
            severity_note = "√≠t m·ª•n"
        elif total_count < 15:
            severity_note = "m·ª©c ƒë·ªô v·ª´a ph·∫£i"
        elif total_count < 30:
            severity_note = "kh√° nhi·ªÅu m·ª•n"
        else:
            severity_note = "nhi·ªÅu m·ª•n, c·∫ßn ƒë·∫∑c bi·ªát ch√∫ √Ω"
        
        condition_text = "\n".join(condition_details)
        additional_info = f"""
## TH√îNG TIN B·ªî SUNG (t·ª´ AI detection model):
**T·ªïng s·ªë v·ªã tr√≠ c√≥ m·ª•n ƒë∆∞·ª£c ph√°t hi·ªán**: {total_count} ({severity_note})

**Chi ti·∫øt c√°c lo·∫°i m·ª•n**:
{condition_text}

*L∆∞u √Ω: Th√¥ng tin tr√™n ch·ªâ mang t√≠nh tham kh·∫£o. H√£y T·ª∞ PH√ÇN T√çCH ·∫£nh m·ªôt c√°ch ƒë·ªôc l·∫≠p v√† ƒë∆∞a ra ƒë√°nh gi√° c·ªßa ri√™ng b·∫°n.*
"""
    
    if custom_prompt:
        base_prompt = custom_prompt
        logger.info("Using custom prompt")
    else:
        # Hard coded comprehensive prompt
        base_prompt = """
# CHUY√äN GIA PH√ÇN T√çCH DA M·∫∂T - T·ª∞ ƒê√ÅNH GI√Å TO√ÄN DI·ªÜN T·ª™ ·∫¢NH

## VAI TR√í C·ª¶A B·∫†N
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch da m·∫∑t h√†ng ƒë·∫ßu v·ªõi 20+ nƒÉm kinh nghi·ªám. Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
- **T·ª∞ QUAN S√ÅT** v√† PH√ÇN T√çCH ·∫£nh khu√¥n m·∫∑t m·ªôt c√°ch chi ti·∫øt
- **NH·∫¨N DI·ªÜN** t·∫•t c·∫£ c√°c v·∫•n ƒë·ªÅ v·ªÅ da: m·ª•n, n√°m, n·∫øp nhƒÉn, l·ªó ch√¢n l√¥ng, ƒë·ªô ƒë√†n h·ªìi, m√†u s·∫Øc
- **ƒê√ÅNH GI√Å TH·ª∞C T·∫æ** d·ª±a tr√™n nh·ªØng g√¨ B·∫†N NH√åN TH·∫§Y trong ·∫£nh
- **T∆Ø V·∫§N GI·∫¢I PH√ÅP** c·ª• th·ªÉ v√† c√≥ th·ªÉ √°p d·ª•ng ngay

## PH∆Ø∆†NG PH√ÅP PH√ÇN T√çCH ·∫¢NH
1. **QUAN S√ÅT T·ªîNG TH·ªÇ**: Nh√¨n to√†n b·ªô khu√¥n m·∫∑t, ƒë√°nh gi√° t·ªïng quan
2. **PH√ÇN T√çCH T·ª™NG V√ôNG**: Chia th√†nh 5 v√πng v√† quan s√°t k·ªπ l∆∞·ª°ng
3. **NH·∫¨N DI·ªÜN V·∫§N ƒê·ªÄ**: T·ª± ph√°t hi·ªán m·ª•n, n√°m, n·∫øp nhƒÉn, l·ªó ch√¢n l√¥ng
4. **ƒê√ÅNH GI√Å M·ª®C ƒê·ªò**: Cho ƒëi·ªÉm t·ª´ 1-10 d·ª±a tr√™n quan s√°t th·ª±c t·∫ø
5. **T∆Ø V·∫§N C·ª§ TH·ªÇ**: ƒê∆∞a ra gi·∫£i ph√°p ph√π h·ª£p v·ªõi nh·ªØng g√¨ th·∫•y ƒë∆∞·ª£c

## NGUY√äN T·∫ÆC ƒê√ÅNH GI√Å
1. **T·ª∞ PH√ÇN T√çCH**: H√£y T·ª∞ NH√åN V√ÄO ·∫¢NH v√† m√¥ t·∫£ chi ti·∫øt nh·ªØng g√¨ b·∫°n th·∫•y
2. **M√î T·∫¢ C·ª§ TH·ªÇ**: N√≥i r√µ v·ªã tr√≠, m√†u s·∫Øc, k√≠ch th∆∞·ªõc, texture c·ªßa t·ª´ng v·∫•n ƒë·ªÅ
3. **ƒê√ÅNH GI√Å TH·ª∞C T·∫æ**: ƒê∆∞a ra m·ª©c ƒë·ªô c·ª• th·ªÉ t·ª´ 1-10 cho t·ª´ng v·∫•n ƒë·ªÅ
4. **T∆Ø V·∫§N THI·∫æT TH·ª∞C**: ƒê·ªÅ xu·∫•t routine chƒÉm s√≥c c·ª• th·ªÉ c√≥ th·ªÉ l√†m ngay
5. **KHUY·∫æN C√ÅO C√ÇN B·∫∞NG**: Ch·ªâ khuy√™n g·∫∑p b√°c sƒ© khi TH·ª∞C S·ª∞ C·∫¶N THI·∫æT

## ƒê·ªäNH D·∫†NG JSON B·∫ÆT BU·ªòC:
```json
{
  "danh_gia_tong_quan": {
    "loai_da": "T·ª∞ X√ÅC ƒê·ªäNH t·ª´ ·∫£nh: Da kh√¥/Da d·∫ßu/Da h·ªón h·ª£p/Da nh·∫°y c·∫£m v·ªõi m√¥ t·∫£ chi ti·∫øt v·ªÅ cƒÉn c·ª© ƒë√°nh gi√°",
    "tinh_trang_chung": "M√¥ t·∫£ TH·ª∞C T·∫æ nh·ªØng g√¨ T·ª∞ QUAN S√ÅT ƒë∆∞·ª£c t·ª´ ·∫£nh, kh√¥ng m∆° h·ªì",
    "diem_manh": ["Li·ªát k√™ c√°c ∆∞u ƒëi·ªÉm c·ª• th·ªÉ NH√åN TH·∫§Y ƒë∆∞·ª£c t·ª´ ·∫£nh"],
    "diem_yeu": ["C√°c v·∫•n ƒë·ªÅ T·ª∞ PH√ÅT HI·ªÜN ƒë∆∞·ª£c v·ªõi m·ª©c ƒë·ªô t·ª´ 1-10"],
    "muc_do_nghiem_trong": "Nh·∫π/V·ª´a/N·∫∑ng v·ªõi L√ù DO C·ª§ TH·ªÇ d·ª±a tr√™n quan s√°t tr·ª±c ti·∫øp"
  },
  "phan_tich_theo_vung": {
    "vung_T": "Ph√¢n t√≠ch CHI TI·∫æT v√πng tr√°n-m≈©i-c·∫±m: texture, d·∫ßu nh·ªùn, m·ª•n, l·ªó ch√¢n l√¥ng",
    "vung_U": "Ph√¢n t√≠ch CHI TI·∫æT v√πng m√°-th√°i d∆∞∆°ng: ƒë·ªô ·∫©m, ƒë·ªÅu m√†u, ƒë·ªô ƒë√†n h·ªìi", 
    "vung_mat": "ƒê√°nh gi√° C·ª§ TH·ªÇ: n·∫øp nhƒÉn, b·ªçng m·∫Øt, qu·∫ßng th√¢m v·ªõi m·ª©c ƒë·ªô",
    "vung_moi": "Ph√¢n t√≠ch m√¥i v√† v√πng quanh m√¥i: ƒë·ªô ·∫©m, m√†u s·∫Øc, n·ª©t n·∫ª",
    "vung_co": "ƒê√°nh gi√° c·ªï v√† h√†m d∆∞·ªõi: ƒë·ªô cƒÉng, m√†u s·∫Øc, texture"
  },
  "chi_tiet_van_de": {
    "mun_trung_ca": {
      "phan_tich_cu_the": "M√¥ t·∫£ CH√çNH X√ÅC t·ª´ng lo·∫°i m·ª•n: v·ªã tr√≠, k√≠ch th∆∞·ªõc, m√†u s·∫Øc, m·ª©c ƒë·ªô vi√™m",
      "nguyen_nhan_chinh": ["X√°c ƒë·ªãnh 2-3 nguy√™n nh√¢n ch√≠nh g√¢y ra t√¨nh tr·∫°ng hi·ªán t·∫°i"],
      "do_nghiem_trong": "Thang ƒëi·ªÉm 1-10 v·ªõi gi·∫£i th√≠ch c·ª• th·ªÉ",
      "xu_huong_phat_trien": "D·ª± ƒëo√°n TH·ª∞C T·∫æ v·ªÅ di·ªÖn bi·∫øn trong 2-4 tu·∫ßn t·ªõi"
    },
    "van_de_khac": {
      "lao_hoa": "ƒê√°nh gi√° n·∫øp nhƒÉn, ch·∫£y x·ªá v·ªõi ƒëi·ªÉm s·ªë 1-10",
      "sac_to": "Ph√¢n t√≠ch n√°m, t√†n nhang, ƒë·ªëm n√¢u v·ªõi v·ªã tr√≠ v√† m·ª©c ƒë·ªô c·ª• th·ªÉ",
      "do_am_dau": "ƒê√°nh gi√° c√¢n b·∫±ng d·∫ßu-n∆∞·ªõc v·ªõi ƒëi·ªÉm s·ªë v√† m√¥ t·∫£",
      "lo_chan_long": "ƒê√°nh gi√° k√≠ch th∆∞·ªõc v√† t√¨nh tr·∫°ng t·∫Øc ngh·∫Ωn"
    }
  },
  "routine_cham_soc_cu_the": {
    "buoi_sang": [
      "B∆∞·ªõc 1: [T√™n s·∫£n ph·∫©m c·ª• th·ªÉ] - C√°ch d√πng - L√Ω do",
      "B∆∞·ªõc 2: [T√™n s·∫£n ph·∫©m c·ª• th·ªÉ] - C√°ch d√πng - L√Ω do",
      "B∆∞·ªõc 3: [T√™n s·∫£n ph·∫©m c·ª• th·ªÉ] - C√°ch d√πng - L√Ω do"
    ],
    "buoi_toi": [
      "B∆∞·ªõc 1: [T√™n s·∫£n ph·∫©m c·ª• th·ªÉ] - C√°ch d√πng - L√Ω do",
      "B∆∞·ªõc 2: [T√™n s·∫£n ph·∫©m c·ª• th·ªÉ] - C√°ch d√πng - L√Ω do", 
      "B∆∞·ªõc 3: [T√™n s·∫£n ph·∫©m c·ª• th·ªÉ] - C√°ch d√πng - L√Ω do"
    ],
    "cham_soc_dac_biet": {
      "2-3_lan_tuan": ["Li·ªáu tr√¨nh c·ª• th·ªÉ v·ªõi t√™n s·∫£n ph·∫©m v√† c√°ch th·ª±c hi·ªán"],
      "hang_thang": ["ƒêi·ªÅu tr·ªã s√¢u v·ªõi s·∫£n ph·∫©m v√† ph∆∞∆°ng ph√°p c·ª• th·ªÉ"],
      "luu_y_quan_trong": ["Nh·ªØng ƒëi·ªÅu TUY·ªÜT ƒê·ªêI kh√¥ng ƒë∆∞·ª£c l√†m"]
    }
  },
  "ket_qua_mong_doi": {
    "sau_2_tuan": "Nh·ªØng thay ƒë·ªïi C·ª§ TH·ªÇ c√≥ th·ªÉ th·∫•y ƒë∆∞·ª£c",
    "sau_1_thang": "M·ª©c ƒë·ªô c·∫£i thi·ªán TH·ª∞C T·∫æ c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c",
    "sau_3_thang": "K·∫øt qu·∫£ d√†i h·∫°n v√† m·ª•c ti√™u ho√†n thi·ªán",
    "chi_phi_uoc_tinh": "∆Ø·ªõc t√≠nh chi ph√≠ routine h√†ng th√°ng"
  },
  "canh_bao_va_khuyen_cao": {
    "can_gap_bac_si": "CH·ªà khuy√™n g·∫∑p b√°c sƒ© khi TH·ª∞C S·ª∞ c·∫ßn thi·∫øt v·ªõi l√Ω do c·ª• th·ªÉ",
    "muc_do_khan_cap": "Kh√¥ng kh·∫©n c·∫•p/N√™n s·ªõm/Kh·∫©n c·∫•p",
    "co_the_tu_cham_soc": "true/false - ƒê√°nh gi√° c√≥ th·ªÉ t·ª± chƒÉm s√≥c t·∫°i nh√† kh√¥ng",
    "dau_hieu_theo_doi": ["C√°c d·∫•u hi·ªáu c·∫ßn theo d√µi trong qu√° tr√¨nh ƒëi·ªÅu tr·ªã"]
  },
  "do_tin_cay_danh_gia": {
    "phan_tram": "T·ª´ 75-95% t√πy theo ƒë·ªô r√µ r√†ng c·ªßa h√¨nh ·∫£nh",
    "han_che": ["C√°c h·∫°n ch·∫ø c·ª• th·ªÉ c·ªßa vi·ªác ƒë√°nh gi√° qua ·∫£nh"],
    "de_xuat_bo_sung": ["G·ª£i √Ω ƒë·ªÉ c√≥ ƒë√°nh gi√° ch√≠nh x√°c h∆°n n·∫øu c·∫ßn"]
  }
}
```

## QUY TR√åNH PH√ÇN T√çCH B·∫ÆT BU·ªòC:

### 1. QUAN S√ÅT V√Ä PH√ÇN T√çCH
- Nh√¨n v√†o h√¨nh ·∫£nh v√† m√¥ t·∫£ CHI TI·∫æT nh·ªØng g√¨ b·∫°n th·∫•y
- ƒê√°nh gi√° m√†u s·∫Øc, texture, ƒë·ªô b√≥ng/m·ªù, l·ªó ch√¢n l√¥ng
- Ph√¢n t√≠ch T·ª™NG V√ôNG m·ªôt c√°ch c·ª• th·ªÉ

### 2. ƒê√ÅNH GI√Å TH·ª∞C T·∫æ
- ƒê∆∞a ra ƒëi·ªÉm s·ªë 1-10 cho t·ª´ng v·∫•n ƒë·ªÅ
- Gi·∫£i th√≠ch C·ª§ TH·ªÇ cƒÉn c·ª© ƒë√°nh gi√°
- So s√°nh v·ªõi ti√™u chu·∫©n b√¨nh th∆∞·ªùng c·ªßa ƒë·ªô tu·ªïi

### 3. T∆Ø V·∫§N THI·∫æT TH·ª∞C
- ƒê·ªÅ xu·∫•t s·∫£n ph·∫©m C·ª§ TH·ªÇ (t√™n th∆∞∆°ng hi·ªáu n·∫øu c√≥ th·ªÉ)
- H∆∞·ªõng d·∫´n c√°ch s·ª≠ d·ª•ng CHI TI·∫æT
- ∆Ø·ªõc t√≠nh th·ªùi gian v√† chi ph√≠

### 4. KHUY·∫æN C√ÅO C√ÇN B·∫∞NG
- CH·ªà khuy√™n g·∫∑p b√°c sƒ© khi TH·∫¨T S·ª∞ c·∫ßn thi·∫øt
- ƒêa s·ªë tr∆∞·ªùng h·ª£p c√≥ th·ªÉ t·ª± chƒÉm s√≥c t·∫°i nh√†
- ƒê∆∞a ra l·ªô tr√¨nh theo d√µi c·ª• th·ªÉ

## Y√äU C·∫¶U QUAN TR·ªåNG:
- PH·∫¢I PH√ÇN T√çCH TH·∫¨T S·ª∞, kh√¥ng ƒë∆∞·ª£c n√≥i chung chung
- PH·∫¢I ƒê∆ØA RA ƒêI·ªÇM S·ªê c·ª• th·ªÉ cho t·ª´ng v·∫•n ƒë·ªÅ
- PH·∫¢I T∆Ø V·∫§N ROUTINE chi ti·∫øt c√≥ th·ªÉ l√†m ngay
- CH·ªà khuy√™n g·∫∑p b√°c sƒ© khi th·ª±c s·ª± c·∫ßn thi·∫øt (< 20% tr∆∞·ªùng h·ª£p)

H√£y tr·ªü th√†nh chuy√™n gia ph√¢n t√≠ch da th·ª±c th·ª• - NH·∫¨N X√âT C·ª§ TH·ªÇ, T∆Ø V·∫§N THI·∫æT TH·ª∞C!
"""
        logger.info("Using hard-coded comprehensive prompt")
    
    enhanced_prompt = f"""{base_prompt}

{additional_info}

## Y√äU C·∫¶U TH·ª∞C HI·ªÜN - T·ª∞ PH√ÇN T√çCH ·∫¢NH
B·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c m·ªôt ·∫£nh khu√¥n m·∫∑t. H√£y:

### B∆Ø·ªöC 1: T·ª∞ QUAN S√ÅT V√Ä M√î T·∫¢
- **Nh√¨n v√†o ·∫£nh** v√† m√¥ t·∫£ chi ti·∫øt nh·ªØng g√¨ b·∫°n th·∫•y
- **Quan s√°t t·ª´ng v√πng**: tr√°n, m≈©i, c·∫±m, m√° tr√°i, m√° ph·∫£i, v√πng m·∫Øt, m√¥i
- **Ph√°t hi·ªán v·∫•n ƒë·ªÅ**: T·ª± t√¨m m·ª•n, n√°m, n·∫øp nhƒÉn, l·ªó ch√¢n l√¥ng, ƒë·ªô ƒë√†n h·ªìi

### B∆Ø·ªöC 2: PH√ÇN T√çCH V√Ä ƒê√ÅNH GI√Å
- **M√¥ t·∫£ c·ª• th·ªÉ** t·ª´ng v·∫•n ƒë·ªÅ: v·ªã tr√≠, k√≠ch th∆∞·ªõc, m√†u s·∫Øc, m·ª©c ƒë·ªô
- **Cho ƒëi·ªÉm s·ªë** t·ª´ 1-10 cho t·ª´ng v·∫•n ƒë·ªÅ d·ª±a tr√™n quan s√°t
- **X√°c ƒë·ªãnh lo·∫°i da** d·ª±a tr√™n texture, ƒë·ªô b√≥ng/m·ªù, l·ªó ch√¢n l√¥ng

### B∆Ø·ªöC 3: T∆Ø V·∫§N TH·ª∞C T·∫æ
- **ƒê∆∞a ra routine** chƒÉm s√≥c ph√π h·ª£p v·ªõi nh·ªØng g√¨ quan s√°t ƒë∆∞·ª£c
- **G·ª£i √Ω s·∫£n ph·∫©m** c·ª• th·ªÉ cho t·ª´ng v·∫•n ƒë·ªÅ
- **D·ª± ƒëo√°n k·∫øt qu·∫£** c√≥ th·ªÉ ƒë·∫°t ƒë∆∞·ª£c

### B∆Ø·ªöC 4: KHUY·∫æN C√ÅO C√ÇN B·∫∞NG
- **Ch·ªâ khuy√™n g·∫∑p b√°c sƒ©** khi th·∫≠t s·ª± c·∫ßn thi·∫øt (< 15% tr∆∞·ªùng h·ª£p)
- **ƒêa s·ªë tr∆∞·ªùng h·ª£p** c√≥ th·ªÉ t·ª± chƒÉm s√≥c hi·ªáu qu·∫£ t·∫°i nh√†

**L∆ØU √ù QUAN TR·ªåNG**: H√£y T·ª∞ PH√ÇN T√çCH ·∫£nh v√† ƒë∆∞a ra ƒë√°nh gi√° d·ª±a tr√™n nh·ªØng g√¨ B·∫†N NH√åN TH·∫§Y, kh√¥ng d·ª±a v√†o th√¥ng tin c√≥ s·∫µn!

H√£y tr·ªü th√†nh chuy√™n gia da li·ªÖu th·ª±c th·ª• v√† ƒë∆∞a ra ph√¢n t√≠ch to√†n di·ªán t·ª´ ch√≠nh ƒë√¥i m·∫Øt c·ªßa b·∫°n!
"""
    
    return enhanced_prompt

def parse_safe_response(response_text: str) -> Dict[str, Any]:
    """Parse Gemini response with focus on safe, structured format."""
    try:
        # Extract JSON from response
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON object
            json_pattern = r'\{.*\}'
            json_match = re.search(json_pattern, response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                # Return structured fallback if no JSON found
                return create_safe_fallback_response(response_text)
        
        # Parse JSON
        parsed_response = json.loads(json_str)
        
        # Validate and ensure required keys exist
        if isinstance(parsed_response, dict):
            # Updated required keys for new format
            required_keys = [
                'danh_gia_tong_quan', 'phan_tich_theo_vung', 'chi_tiet_van_de', 
                'routine_cham_soc_cu_the', 'ket_qua_mong_doi', 'canh_bao_va_khuyen_cao'
            ]
            
            # Add missing keys with safe defaults
            for key in required_keys:
                if key not in parsed_response:
                    parsed_response[key] = get_safe_default_value(key)
            
            return {
                "phan_tich": parsed_response,
                "dinh_dang": "json_co_cau_truc",
                "xu_ly_thanh_cong": True
            }
        
        return create_safe_fallback_response(response_text)
        
    except (json.JSONDecodeError, ValueError) as e:
        logger.warning(f"JSON parsing failed: {e}")
        return create_safe_fallback_response(response_text, str(e))

def get_safe_default_value(key: str) -> Any:
    """Return default values for missing keys in new format."""
    defaults = {
        'danh_gia_tong_quan': {
            "loai_da": "C·∫ßn ƒë√°nh gi√° th√™m ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c",
            "tinh_trang_chung": "ƒê√£ ph√¢n t√≠ch c∆° b·∫£n, c·∫ßn th√¥ng tin th√™m ƒë·ªÉ ƒë√°nh gi√° chi ti·∫øt",
            "diem_manh": ["Da c√≥ v·∫ª kh·ªèe m·∫°nh t·ªïng th·ªÉ"],
            "diem_yeu": ["C√≥ m·ªôt s·ªë v·∫•n ƒë·ªÅ c·∫ßn c·∫£i thi·ªán"],
            "muc_do_nghiem_trong": "V·ª´a ph·∫£i - c·∫ßn theo d√µi v√† chƒÉm s√≥c ƒë√∫ng c√°ch"
        },
        'phan_tich_theo_vung': {
            "vung_T": "V√πng T c√≥ d·∫•u hi·ªáu ti·∫øt d·∫ßu, c·∫ßn ki·ªÉm so√°t",
            "vung_U": "V√πng U c·∫ßn c√¢n b·∫±ng ƒë·ªô ·∫©m",
            "vung_mat": "V√πng m·∫Øt c·∫ßn chƒÉm s√≥c ƒë·∫∑c bi·ªát",
            "vung_moi": "M√¥i c·∫ßn d∆∞·ª°ng ·∫©m",
            "vung_co": "C·ªï c·∫ßn ch√∫ √Ω l√†m s·∫°ch"
        },
        'chi_tiet_van_de': {
            "mun_trung_ca": {
                "phan_tich_cu_the": "C√≥ m·ª•n ·ªü m·ª©c ƒë·ªô v·ª´a ph·∫£i",
                "nguyen_nhan_chinh": ["Ti·∫øt d·∫ßu d∆∞ th·ª´a", "ChƒÉm s√≥c ch∆∞a ƒë√∫ng c√°ch"],
                "do_nghiem_trong": "5/10 - m·ª©c ƒë·ªô trung b√¨nh",
                "xu_huong_phat_trien": "C√≥ th·ªÉ c·∫£i thi·ªán v·ªõi chƒÉm s√≥c ƒë√∫ng c√°ch"
            },
            "van_de_khac": {
                "lao_hoa": "Ch∆∞a c√≥ d·∫•u hi·ªáu l√£o h√≥a r√µ r·ªát - 3/10",
                "sac_to": "M√†u da t∆∞∆°ng ƒë·ªëi ƒë·ªÅu - 4/10",
                "do_am_dau": "C·∫ßn c√¢n b·∫±ng d·∫ßu-n∆∞·ªõc - 6/10",
                "lo_chan_long": "L·ªó ch√¢n l√¥ng h∆°i to - 5/10"
            }
        },
        'routine_cham_soc_cu_the': {
            "buoi_sang": [
                "B∆∞·ªõc 1: S·ªØa r·ª≠a m·∫∑t d·ªãu nh·∫π - Massage 30 gi√¢y - L√†m s·∫°ch kh√¥ng kh√¥ da",
                "B∆∞·ªõc 2: Toner c√¢n b·∫±ng pH - Th·∫•m nh·∫π - Chu·∫©n b·ªã cho c√°c b∆∞·ªõc ti·∫øp theo",
                "B∆∞·ªõc 3: Kem ch·ªëng n·∫Øng SPF 30+ - Thoa ƒë·ªÅu - B·∫£o v·ªá kh·ªèi tia UV"
            ],
            "buoi_toi": [
                "B∆∞·ªõc 1: T·∫©y trang k·ªπ l∆∞·ª°ng - Massage nh·∫π - Lo·∫°i b·ªè b·ª•i b·∫©n",
                "B∆∞·ªõc 2: S·ªØa r·ª≠a m·∫∑t - L√†m s·∫°ch s√¢u - Chu·∫©n b·ªã da h·∫•p th·ª•",
                "B∆∞·ªõc 3: Serum/kem d∆∞·ª°ng - Thoa nh·∫π - Ph·ª•c h·ªìi v√† d∆∞·ª°ng da"
            ],
            "cham_soc_dac_biet": {
                "2-3_lan_tuan": ["M·∫∑t n·∫° ƒë·∫•t s√©t - H√∫t d·∫ßu th·ª´a - L√†m s·∫°ch l·ªó ch√¢n l√¥ng"],
                "hang_thang": ["ƒêi·ªÅu tr·ªã chuy√™n s√¢u t·∫°i spa - T√πy theo ng√¢n s√°ch"],
                "luu_y_quan_trong": ["Kh√¥ng n·∫∑n m·ª•n b·∫±ng tay", "Th·ª≠ patch test tr∆∞·ªõc khi d√πng s·∫£n ph·∫©m m·ªõi"]
            }
        },
        'ket_qua_mong_doi': {
            "sau_2_tuan": "Da s·∫°ch h∆°n, √≠t b√≥ng d·∫ßu h∆°n",
            "sau_1_thang": "M·ª•n gi·∫£m 60-70%, da ƒë·ªÅu m√†u h∆°n",
            "sau_3_thang": "Da kh·ªèe m·∫°nh, m·ªãn m√†ng, √≠t m·ª•n r√µ r·ªát",
            "chi_phi_uoc_tinh": "300-500k VND/th√°ng cho routine c∆° b·∫£n"
        },
        'canh_bao_va_khuyen_cao': {
            "can_gap_bac_si": "Kh√¥ng c·∫ßn thi·∫øt - c√≥ th·ªÉ t·ª± chƒÉm s√≥c t·∫°i nh√†",
            "muc_do_khan_cap": "Kh√¥ng kh·∫©n c·∫•p",
            "co_the_tu_cham_soc": "true",
            "dau_hieu_theo_doi": ["Da ƒë·ªè b·∫•t th∆∞·ªùng", "M·ª•n tƒÉng nhi·ªÅu ƒë·ªôt ng·ªôt", "C√≥ d·∫•u hi·ªáu d·ªã ·ª©ng"]
        }
    }
    return defaults.get(key, {"thong_tin": "C·∫ßn ƒë√°nh gi√° th√™m"})

def create_safe_fallback_response(response_text: str, error: str = None) -> Dict[str, Any]:
    """Create a comprehensive fallback response structure."""
    return {
        "phan_tich": {
            "danh_gia_tong_quan": {
                "loai_da": "Da h·ªón h·ª£p - c·∫ßn ƒë√°nh gi√° th√™m ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c",
                "tinh_trang_chung": "Ph√°t hi·ªán m·ªôt s·ªë v·∫•n ƒë·ªÅ v·ªÅ m·ª•n tr√™n da. T√¨nh tr·∫°ng t·ªïng th·ªÉ ·ªü m·ª©c trung b√¨nh, c√≥ th·ªÉ c·∫£i thi·ªán v·ªõi chƒÉm s√≥c ƒë√∫ng c√°ch.",
                "diem_manh": ["Da c√≥ ƒë·ªô ƒë√†n h·ªìi t·ªët", "M√†u s·∫Øc t∆∞∆°ng ƒë·ªëi ƒë·ªÅu"],
                "diem_yeu": ["C√≥ m·ª•n c·∫ßn ƒëi·ªÅu tr·ªã - 6/10", "C·∫ßn c√¢n b·∫±ng d·∫ßu-n∆∞·ªõc - 5/10"],
                "muc_do_nghiem_trong": "V·ª´a ph·∫£i - c√≥ th·ªÉ t·ª± chƒÉm s√≥c t·∫°i nh√† v·ªõi routine ph√π h·ª£p"
            },
            "phan_tich_theo_vung": {
                "vung_T": "V√πng T (tr√°n-m≈©i-c·∫±m) c√≥ d·∫•u hi·ªáu ti·∫øt d·∫ßu nhi·ªÅu, l·ªó ch√¢n l√¥ng h∆°i to, xu·∫•t hi·ªán m·ªôt s·ªë m·ª•n c·∫ßn ƒëi·ªÅu tr·ªã",
                "vung_U": "V√πng U (m√°-th√°i d∆∞∆°ng) t∆∞∆°ng ƒë·ªëi ·ªïn ƒë·ªãnh, c·∫ßn d∆∞·ª°ng ·∫©m ƒë·ªÉ c√¢n b·∫±ng", 
                "vung_mat": "V√πng m·∫Øt ch∆∞a c√≥ d·∫•u hi·ªáu l√£o h√≥a r√µ r·ªát, c·∫ßn chƒÉm s√≥c ƒë·ªÉ ph√≤ng ng·ª´a",
                "vung_moi": "M√¥i c·∫ßn d∆∞·ª°ng ·∫©m th∆∞·ªùng xuy√™n",
                "vung_co": "V√πng c·ªï c·∫ßn ch√∫ √Ω v·ªá sinh v√† d∆∞·ª°ng ·∫©m"
            },
            "chi_tiet_van_de": {
                "mun_trung_ca": {
                    "phan_tich_cu_the": "M·ª•n ch·ªß y·∫øu t·∫≠p trung ·ªü v√πng T, c√≥ c·∫£ m·ª•n ƒë·∫ßu ƒëen v√† m·ª•n vi√™m nh·∫π",
                    "nguyen_nhan_chinh": ["Ti·∫øt d·∫ßu d∆∞ th·ª´a", "T·∫Øc ngh·∫Ωn l·ªó ch√¢n l√¥ng", "ChƒÉm s√≥c ch∆∞a ƒë√∫ng c√°ch"],
                    "do_nghiem_trong": "6/10 - m·ª©c ƒë·ªô trung b√¨nh, c√≥ th·ªÉ ƒëi·ªÅu tr·ªã t·∫°i nh√†",
                    "xu_huong_phat_trien": "C√≥ th·ªÉ c·∫£i thi·ªán 70-80% trong 1-2 th√°ng v·ªõi chƒÉm s√≥c ƒë√∫ng c√°ch"
                },
                "van_de_khac": {
                    "lao_hoa": "Ch∆∞a c√≥ d·∫•u hi·ªáu l√£o h√≥a r√µ r·ªát - 2/10",
                    "sac_to": "M√†u da t∆∞∆°ng ƒë·ªëi ƒë·ªÅu, m·ªôt v√†i v·∫øt th√¢m nh·∫π - 4/10",
                    "do_am_dau": "M·∫•t c√¢n b·∫±ng d·∫ßu-n∆∞·ªõc, v√πng T d·∫ßu, v√πng U kh√¥ - 6/10",
                    "lo_chan_long": "L·ªó ch√¢n l√¥ng h∆°i to ·ªü v√πng T - 5/10"
                }
            },
            "routine_cham_soc_cu_the": {
                "buoi_sang": [
                    "B∆∞·ªõc 1: S·ªØa r·ª≠a m·∫∑t d√†nh cho da d·∫ßu/h·ªón h·ª£p - Massage 30-60s - L√†m s·∫°ch d·∫ßu th·ª´a",
                    "B∆∞·ªõc 2: Toner kh√¥ng c·ªìn - D√πng b√¥ng t·∫©y trang th·∫•m nh·∫π - C√¢n b·∫±ng pH",
                    "B∆∞·ªõc 3: Serum vitamin C - Thoa nh·∫π v√πng U - Ch·ªëng oxy h√≥a",
                    "B∆∞·ªõc 4: Kem ch·ªëng n·∫Øng SPF 30+ - Thoa ƒë·ªÅu to√†n m·∫∑t - B·∫£o v·ªá da"
                ],
                "buoi_toi": [
                    "B∆∞·ªõc 1: D·∫ßu t·∫©y trang ho·∫∑c micellar - Massage nh·∫π - Lo·∫°i b·ªè makeup v√† b·ª•i b·∫©n",
                    "B∆∞·ªõc 2: S·ªØa r·ª≠a m·∫∑t - L√†m s·∫°ch s√¢u - Chu·∫©n b·ªã cho c√°c b∆∞·ªõc ti·∫øp theo",
                    "B∆∞·ªõc 3: BHA 2% (3 l·∫ßn/tu·∫ßn) - Thoa v√πng T - L√†m s·∫°ch l·ªó ch√¢n l√¥ng",
                    "B∆∞·ªõc 4: Kem d∆∞·ª°ng nh·∫π - Thoa ƒë·ªÅu - Ph·ª•c h·ªìi v√† d∆∞·ª°ng ·∫©m"
                ],
                "cham_soc_dac_biet": {
                    "2-3_lan_tuan": ["M·∫∑t n·∫° ƒë·∫•t s√©t - 10-15 ph√∫t - H√∫t d·∫ßu v√† l√†m s·∫°ch l·ªó ch√¢n l√¥ng"],
                    "hang_thang": ["T·∫©y da ch·∫øt nh·∫π", "ƒêi·ªÅu tr·ªã facial c∆° b·∫£n n·∫øu c√≥ ƒëi·ªÅu ki·ªán"],
                    "luu_y_quan_trong": ["KH√îNG n·∫∑n m·ª•n b·∫±ng tay", "Patch test s·∫£n ph·∫©m m·ªõi", "U·ªëng ƒë·ªß n∆∞·ªõc 2L/ng√†y"]
                }
            },
            "ket_qua_mong_doi": {
                "sau_2_tuan": "Da s·∫°ch h∆°n, √≠t b√≥ng d·∫ßu, m·ª•n m·ªõi gi·∫£m 50%",
                "sau_1_thang": "M·ª•n hi·ªán t·∫°i gi·∫£m 70%, da ƒë·ªÅu m√†u v√† m·ªãn h∆°n",
                "sau_3_thang": "Da kh·ªèe m·∫°nh, m·ª•n ch·ªâ c√≤n 10-20%, texture da c·∫£i thi·ªán r√µ r·ªát",
                "chi_phi_uoc_tinh": "400-600k VND/th√°ng cho routine ƒë·∫ßy ƒë·ªß"
            },
            "canh_bao_va_khuyen_cao": {
                "can_gap_bac_si": "KH√îNG c·∫ßn thi·∫øt ngay - c√≥ th·ªÉ t·ª± chƒÉm s√≥c hi·ªáu qu·∫£ t·∫°i nh√†",
                "muc_do_khan_cap": "Kh√¥ng kh·∫©n c·∫•p",
                "co_the_tu_cham_soc": "true",
                "dau_hieu_theo_doi": ["Da ƒë·ªè b·∫•t th∆∞·ªùng sau d√πng s·∫£n ph·∫©m", "M·ª•n tƒÉng ƒë·ªôt ng·ªôt", "C√≥ m·ª•n b·ªçc to v√† ƒëau"]
            },
            "do_tin_cay_danh_gia": {
                "phan_tram": "75%",
                "han_che": ["ƒê√°nh gi√° qua ·∫£nh kh√¥ng th·ªÉ thay th·∫ø kh√°m tr·ª±c ti·∫øp", "√Ånh s√°ng ·∫£nh c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·ªô ch√≠nh x√°c"],
                "de_xuat_bo_sung": ["Ch·ª•p ·∫£nh trong √°nh s√°ng t·ª± nhi√™n ƒë·ªÉ ƒë√°nh gi√° ch√≠nh x√°c h∆°n"]
            }
        },
        "phan_tich_goc": response_text,
        "dinh_dang": "fallback_thuc_te",
        "xu_ly_thanh_cong": False,
        "loi_xu_ly": error
    }

@router.post("/analyze")
async def analyze_with_gemini(
    request_data: GeminiRequest,
    token: str = Depends(JWTBearer())
):
    """
    Analyze skin image with Gemini AI - Direct image analysis approach.
    
    Args:
        request_data: Contains base64 image (required), optional pre-detected acne summary, and analysis type
        token: JWT authentication token
        
    Returns:
        JSONResponse with comprehensive, structured analysis results based on direct image observation
    """
    start_time = datetime.now()
    
    try:
        # Validate required data
        if not request_data.image_base64:
            raise HTTPException(status_code=400, detail="image_base64 l√† b·∫Øt bu·ªôc")
        
        try:
            fixed_b64 = fix_base64_padding(request_data.image_base64)
            image_content = base64.b64decode(fixed_b64)
            logger.info(f"ƒê√£ x·ª≠ l√Ω ·∫£nh th√†nh c√¥ng, k√≠ch th∆∞·ªõc: {len(image_content)} bytes")
        except Exception as decode_err:
            logger.error(f"L·ªói gi·∫£i m√£ base64: {decode_err}")
            raise HTTPException(status_code=400, detail=f"D·ªØ li·ªáu ·∫£nh base64 kh√¥ng h·ª£p l·ªá: {str(decode_err)}")
        
        # Detect image format
        mime_type = "image/jpeg"  # default
        if image_content.startswith(b'\x89PNG'):
            mime_type = "image/png"
        elif image_content.startswith(b'GIF'):
            mime_type = "image/gif"
        elif image_content.startswith(b'\xff\xd8\xff'):
            mime_type = "image/jpeg"
            
        logger.info(f"ƒê·ªãnh d·∫°ng ·∫£nh: {mime_type}")
        
        # Configure Gemini with conservative settings for medical analysis
        generation_config = genai.types.GenerationConfig(
            temperature=0.1,  # Very low temperature for consistent medical advice
            top_p=0.7,
            top_k=30,
            max_output_tokens=2048,
        )
        
        model = genai.GenerativeModel(
            'gemini-1.5-flash',
            generation_config=generation_config
        )
        
        # Prepare image data
        image_data = {
            "mime_type": mime_type,
            "data": image_content
        }
        
        # Build safe prompt
        safe_prompt = build_enhanced_safe_prompt(
            request_data.class_summary,  # Now optional
            request_data.analysis_type or "default",
            request_data.custom_prompt
        )
        
        # Print prompt being sent
        print("\n" + "="*80)
        print("üìù PROMPT SENT TO GEMINI:")
        print("="*80)
        print(safe_prompt[:1000] + "..." if len(safe_prompt) > 1000 else safe_prompt)
        print("="*80 + "\n")
        
        logger.info("ƒêang g·ª≠i y√™u c·∫ßu t·ªõi Gemini API")
        
        # Get AI response
        try:
            response = model.generate_content([safe_prompt, image_data])
            logger.info("ƒê√£ nh·∫≠n ph·∫£n h·ªìi t·ª´ Gemini API")
            
            # Print raw response from Gemini
            print("\n" + "="*80)
            print("ü§ñ GEMINI RAW RESPONSE:")
            print("="*80)
            print(response.text)
            print("="*80 + "\n")
            
        except Exception as api_error:
            logger.error(f"L·ªói Gemini API: {api_error}")
            raise HTTPException(status_code=503, detail=f"D·ªãch v·ª• AI t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng: {str(api_error)}")
        
        # Parse response safely
        parsed_result = parse_safe_response(response.text)
        
        # Print parsed result
        print("\n" + "="*80)
        print("üìä PARSED RESULT:")
        print("="*80)
        print(json.dumps(parsed_result, ensure_ascii=False, indent=2))
        print("="*80 + "\n")
        # Prepare final response in Vietnamese
        response_content = {
            "result": parsed_result["phan_tich"],
            "notice": "K·∫øt qu·∫£ n√†y ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o. H√£y tham kh·∫£o √Ω ki·∫øn b√°c sƒ© da li·ªÖu ƒë·ªÉ c√≥ l·ªùi khuy√™n ch√≠nh x√°c nh·∫•t."
        }
        
        # Add error info if exists
        if "error" in parsed_result:
            response_content["error"] = parsed_result["error"]
        
        if "original_analysis" in parsed_result:
            response_content["original_analysis"] = parsed_result["original_analysis"]
        
        # Print final response to client
        print("\n" + "="*80)
        print("üéØ FINAL RESPONSE TO CLIENT:")
        print("="*80)
        print(json.dumps(response_content, ensure_ascii=False, indent=2))
        print("="*80 + "\n")
        
        return JSONResponse(content=response_content)
        
    except HTTPException as he:
        logger.error(f"HTTP Exception: {he.detail}")
        raise he
    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"Unexpected error after {processing_time:.2f}s: {e}")
        
        error_detail = {
            "error_type": type(e).__name__,
            "error_message": str(e),
            "status": "failed",
            "processing_time": round(processing_time, 2),
            "time": datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        }
        raise HTTPException(status_code=500, detail=error_detail)
